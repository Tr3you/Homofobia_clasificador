{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logic.text_processing import TextProcessing\n",
    "from logic.lexical_vectorizer import LexicalVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "from logic.stratified_sampling import random_stratified_sampling\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import FeatureUnion\n",
    "\n",
    "from root import DIR_INPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_procesing = TextProcessing(lang='es')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Preprocesamiento**\n",
    "\n",
    "### Descripción del contenido de las columnas\n",
    "\n",
    "- Id : Identificación unica del tweet\n",
    "- Date : Tiempo universal coordinado (UTC) en el que el tweet fue creado\n",
    "- Tweet : Texto en formato UTF8 de la actualización de estado\n",
    "- Event : Indica si un tweet promueve o no la homofobia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# se cargan los datos\n",
    "df = pd.read_csv('{0}{1}.csv'.format(DIR_INPUT, 'homofobia'), sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#verificacion de valores faltantes por columna\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estadisticos categoricos para la columna objetivo \n",
    "df['Event'] = df['Event'].astype(str)\n",
    "df['Event'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gráficas y distribuciones de frecuencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2,figsize=(15,8))\n",
    "pos = np.arange(len(df['Event'].unique()[:2]))\n",
    "bar = sns.countplot(ax=axes[0],x='Event',data=df ,order = df['Event'].value_counts().index)\n",
    "axes[0].tick_params(top=False, bottom=False, left=False, right=False, labelleft=False, labelbottom=True)\n",
    "for p in bar.patches:\n",
    "    bar.annotate(p.get_height(), \n",
    "                   (p.get_x() + p.get_width() / 2., p.get_height()), \n",
    "                   ha = 'center', va = 'center', \n",
    "                   xytext = (0, 9), \n",
    "                   textcoords = 'offset points')\n",
    "for pos in ['right', 'top', 'bottom', 'left']:\n",
    "    axes[0].spines[pos].set_visible(False)\n",
    "bar.set_ylabel('')\n",
    "bar.set_xlabel('Evento', size=13)\n",
    "bar.set_title('Conteo de tweets por evento: 1 si hay homofobia 0 si no hay', size=15)\n",
    "pie = axes[1].pie(x=df['Event'].value_counts(),labels = df['Event'].unique()[:2],autopct='%.0f%%')\n",
    "_=axes[1].set_title('Distribución de los eventos', size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aplicamos el metodo transformer de la clase TextProcesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Clean_tweet'] = [text_procesing.transformer(row) for row in df['Tweet'].tolist()]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividimos el dataset usando muestreo aleatorio estratificado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, x_test, y_test = random_stratified_sampling(df,y='Event',test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verificacion del balanceo de las clases tanto para las pruebas como para el entrenamiento\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Extraccion de caracteristicas**\n",
    "\n",
    "### Usaremos TF-IDF y vectorizacion lexica a traves de union de caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer(min_df=2, max_df=0.5, ngram_range=(1, 2))\n",
    "lexical_vectorizer = LexicalVectorizer(lang='es', text_processing=text_procesing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_union = FeatureUnion([\n",
    "            ('tfidf_vector', tfidf_vector),\n",
    "            ('lexical_vector', lexical_vectorizer)\n",
    "        ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_union.fit(x_train['Clean_tweet'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b92be554384a9b65063dc092b85fa98f16e236c2cc36010cbeef8adfee466f08"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
